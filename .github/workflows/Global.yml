name: Process Global URLs

on:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 0 * * *' # 每天 UTC 时间 00:00 运行
  workflow_dispatch: # 允许手动触发

jobs:
  process-urls:
    runs-on: ubuntu-latest

    steps:
    # 检出代码
    - name: Checkout repository
      uses: actions/checkout@v4

    # 设置 Python 环境（备用，当前脚本无需 Python）
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'

    # 创建必要的目录
    - name: Create directories
      run: |
        mkdir -p output
        mkdir -p logs

    # 下载 Global_urls.txt 并处理
    - name: Download and process URLs
      run: |
        # 初始化日志文件，确保每次运行都更新
        echo "Download log for run at $(date -u)" > logs/Global_failed_downloads.log

        # 下载主列表
        if ! wget -O Global_urls.txt https://raw.githubusercontent.com/cs2021hv001/Global_Compilation/refs/heads/main/Global_urls.txt; then
          echo "Failed to download Global_urls.txt" >> logs/Global_failed_downloads.log
          exit 1
        fi

        # 创建临时文件存储合并结果
        touch temp_merged.txt
        echo "Created temp_merged.txt" >> logs/Global_failed_downloads.log

        # 调试：输出 Global_urls.txt 内容
        echo "Contents of Global_urls.txt:" >> logs/Global_failed_downloads.log
        cat Global_urls.txt >> logs/Global_failed_downloads.log

        # 读取 Global_urls.txt 中的每个 URL 并下载
        while IFS= read -r url; do
          # 跳过空行
          if [ -z "$url" ]; then
            echo "Skipping empty URL" >> logs/Global_failed_downloads.log
            continue
          fi
          # 下载每个 URL 的内容
          filename=$(basename "$url")
          echo "Downloading $url" >> logs/Global_failed_downloads.log
          if wget -O "temp_$filename" "$url"; then
            # 处理文件：删除注释、DOMAIN-、IP- 开头的行
            sed '/^#/d; /^DOMAIN-/d; /^IP-/d' "temp_$filename" >> temp_merged.txt
            echo "Processed temp_$filename" >> logs/Global_failed_downloads.log
          else
            echo "Failed to download $url" >> logs/Global_failed_downloads.log
          fi
        done < Global_urls.txt

        # 调试：检查 temp_merged.txt 是否有内容
        if [ -s temp_merged.txt ]; then
          echo "temp_merged.txt has content" >> logs/Global_failed_downloads.log
        else
          echo "Warning: temp_merged.txt is empty" >> logs/Global_failed_downloads.log
        fi

        # 处理合并后的文件：删除 server=/ 和 /114.114.114.114
        sed '/server=\//d; /\/114\.114\.114\.114/d' temp_merged.txt > temp_cleaned.txt

        # 调试：检查 temp_cleaned.txt 是否有内容
        if [ -s temp_cleaned.txt ]; then
          echo "temp_cleaned.txt has content" >> logs/Global_failed_downloads.log
        else
          echo "Warning: temp_cleaned.txt is empty" >> logs/Global_failed_downloads.log
        fi

        # 去重并生成最终文件
        sort temp_cleaned.txt | uniq > output/Global_List.conf

        # 调试：检查 Global_List.conf 是否有内容
        if [ -s output/Global_List.conf ]; then
          echo "Global_List.conf generated successfully" >> logs/Global_failed_downloads.log
        else
          echo "Warning: Global_List.conf is empty" >> logs/Global_failed_downloads.log
        fi

        # 清理临时文件，忽略不存在的文件
        rm -f temp_*.txt temp_merged.txt temp_cleaned.txt
        echo "Cleaned up temporary files" >> logs/Global_failed_downloads.log

    # 提交更改
    - name: Commit changes
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        # 强制更新文件时间戳，确保每次运行都提交
        touch output/Global_List.conf logs/Global_failed_downloads.log
        git add output/Global_List.conf logs/Global_failed_downloads.log
        git commit -m "Update Global_List.conf and Global_failed_downloads.log for run at $(date -u)" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
